{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObCkwXNS682ZjLwo31tLbn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DkZbPHOAJtI","executionInfo":{"status":"ok","timestamp":1684432880489,"user_tz":300,"elapsed":58777,"user":{"displayName":"Melissa Tamayo","userId":"11906571870310330412"}},"outputId":"fd608f9b-cc7d-464a-df50-1f930988ee9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","15/15 [==============================] - 0s 2ms/step\n","Precisión: 0.5895833333333333\n"]}],"source":["!pip install numpy\n","!pip install scikit-learn\n","!pip install tensorflow\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score\n","\n","# Cargar los datos desde el archivo CSV\n","data = pd.read_csv('winequality-red.csv', delimiter=';')\n","\n","# Separar características y variable de salida\n","X = data.drop('quality', axis=1)\n","y = data['quality']\n","\n","# Escalar características\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Dividir datos en conjuntos de entrenamiento y validación\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Crear el modelo de perceptrón multicapa\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","# Compilar el modelo\n","model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['mean_squared_error'])\n","\n","# Entrenar el modelo\n","model.fit(X_train, y_train, epochs=280, batch_size=15, verbose=0)\n","\n","# Predecir en el conjunto de validación\n","y_pred = model.predict(X_val)\n","y_pred = y_pred.round().astype(int)\n","\n","# Calcular la precisión en el conjunto de validación\n","accuracy = accuracy_score(y_val, y_pred)\n","print('Precisión:', accuracy)\n"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# Cargar los datos desde el archivo CSV\n","data = pd.read_csv('winequality-red.csv', delimiter=';')\n","\n","# Separar características y variable de salida\n","X = data.drop('quality', axis=1)\n","y = data['quality']\n","\n","# Dividir datos en conjuntos de entrenamiento y validación\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Crear el modelo de regresión lineal\n","model = LinearRegression()\n","\n","# Entrenar el modelo\n","model.fit(X_train, y_train)\n","\n","# Predecir en el conjunto de validación\n","y_pred = model.predict(X_val)\n","\n","# Calcular el error cuadrático medio en el conjunto de validación\n","mse = mean_squared_error(y_val, y_pred)\n","print('Error cuadrático medio:', mse)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVQajJTrA021","executionInfo":{"status":"ok","timestamp":1684424862981,"user_tz":300,"elapsed":281,"user":{"displayName":"Melissa Tamayo","userId":"11906571870310330412"}},"outputId":"dcc7462b-acdd-4f97-f09a-a287549592f1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Error cuadrático medio: 0.41123487175042034\n"]}]},{"cell_type":"markdown","source":["Al comparar los resultados de la regresión lineal y del perceptrón multicapa, se puede observar que el error cuadrático medio de la regresión lineal será uno de los valores de referencia para evaluar el rendimiento del perceptrón multicapa.\n","\n","El perceptrón multicapa tiene la capacidad de aprender relaciones no lineales entre las características de entrada y la variable de salida, lo que le permite modelar de manera más flexible y capturar patrones más complejos en los datos. Esto puede resultar en un mejor desempeño en la predicción en comparación con la regresión lineal, especialmente en conjuntos de datos con características no lineales.\n","\n","Sin embargo, no se puede determinar de antemano cuál modelo tendrá un mejor rendimiento en todos los casos. Dependerá de la naturaleza de los datos y de la relación entre las características y la variable de salida. Por lo tanto, es importante probar diferentes modelos y comparar sus resultados para determinar cuál es el más adecuado para un problema específico."],"metadata":{"id":"QaCnUvDQGFfN"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Cargar el dataset\n","data = pd.read_csv('bank.csv', delimiter=';')\n","\n","# Convertir variables categóricas a numéricas\n","label_encoder = LabelEncoder()\n","data['y'] = label_encoder.fit_transform(data['y'])\n","\n","# Separar las características (X) y las etiquetas (y)\n","X = data.drop('y', axis=1)\n","y = data['y']\n","\n","# Convertir variables categóricas en columnas binarias\n","X = pd.get_dummies(X)\n","\n","# Dividir el dataset en conjuntos de entrenamiento y validación\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Normalizar características\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Crear y entrenar el perceptrón multicapa\n","model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam')\n","model.fit(X_train, y_train)\n","\n","# Realizar predicciones en el conjunto de validación\n","y_pred = model.predict(X_val)\n","\n","# Calcular la exactitud en el conjunto de validación\n","accuracy = accuracy_score(y_val, y_pred)\n","print(\"Exactitud en el conjunto de validación:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJ-VSLOWImTL","executionInfo":{"status":"ok","timestamp":1684424889908,"user_tz":300,"elapsed":12923,"user":{"displayName":"Melissa Tamayo","userId":"11906571870310330412"}},"outputId":"433bd478-a946-4022-ad08-f7772d120f8b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Exactitud en el conjunto de validación: 0.8909358879882093\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["hidden_layer_sizes: En este caso, se ha utilizado una configuración de capas ocultas con 64 y 32 neuronas respectivamente. Estos valores pueden ser ajustados y experimentados según las características y la complejidad del problema. En general, agregar más capas o más neuronas puede permitir al modelo aprender representaciones más complejas, pero también puede aumentar el riesgo de sobreajuste. Por otro lado, usar menos capas o neuronas puede limitar la capacidad de aprendizaje del modelo. La elección de estos valores específicos puede variar según el problema y se recomienda realizar pruebas y validación cruzada para encontrar la configuración óptima.\n","\n","activation: Se ha utilizado la función de activación 'relu', que es una opción común para las capas ocultas en redes neuronales. La función 'relu' (Rectified Linear Unit) es no lineal y permite al modelo aprender relaciones no lineales entre las características de entrada y las salidas. Otros valores posibles para la función de activación son 'logistic', 'tanh' y 'identity', dependiendo del problema y la naturaleza de los datos. Nuevamente, se recomienda probar diferentes opciones y evaluar el rendimiento del modelo.\n","\n","solver: Se ha seleccionado el optimizador 'adam' para entrenar el perceptrón multicapa. Adam es un optimizador eficiente y ampliamente utilizado que combina el método del descenso del gradiente estocástico con adaptación de tasas de aprendizaje individuales para cada parámetro. Funciona bien en una variedad de problemas y es capaz de ajustar eficientemente los hiperparámetros internos del modelo. Otros optimizadores populares son 'sgd' (descenso de gradiente estocástico) y 'lbfgs' (aproximación de la matriz Hessiana inversa limitada). La elección del optimizador también puede influir en la velocidad de convergencia y el rendimiento del modelo, por lo que se recomienda experimentar con diferentes opciones."],"metadata":{"id":"DPVMKvoFObx1"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Cargar el dataset\n","data = pd.read_csv('bank.csv', delimiter=';')\n","\n","# Convertir variables categóricas a numéricas\n","label_encoder = LabelEncoder()\n","data['y'] = label_encoder.fit_transform(data['y'])\n","\n","# Separar las características (X) y las etiquetas (y)\n","X = data.drop('y', axis=1)\n","y = data['y']\n","\n","# Convertir variables categóricas en columnas binarias\n","X = pd.get_dummies(X)\n","\n","# Dividir el dataset en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Normalizar características\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Crear y entrenar el clasificador de regresión logística\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Realizar predicciones en el conjunto de prueba\n","y_pred = model.predict(X_test)\n","\n","# Calcular la exactitud en el conjunto de prueba\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Exactitud en el conjunto de prueba (Regresión Logística):\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CA5XpSfNdtS","executionInfo":{"status":"ok","timestamp":1684424889909,"user_tz":300,"elapsed":30,"user":{"displayName":"Melissa Tamayo","userId":"11906571870310330412"}},"outputId":"746018cb-6406-404b-ee07-5b44a35e2f56"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Exactitud en el conjunto de prueba (Regresión Logística): 0.8983050847457628\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Cargar el dataset\n","data = pd.read_csv('bank.csv', delimiter=';')\n","\n","# Convertir variables categóricas a numéricas\n","label_encoder = LabelEncoder()\n","data['y'] = label_encoder.fit_transform(data['y'])\n","\n","# Separar las características (X) y las etiquetas (y)\n","X = data.drop('y', axis=1)\n","y = data['y']\n","\n","# Convertir variables categóricas en columnas binarias\n","X = pd.get_dummies(X)\n","\n","# Dividir el dataset en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Crear y entrenar el clasificador Naive Bayes\n","model = GaussianNB()\n","model.fit(X_train, y_train)\n","\n","# Realizar predicciones en el conjunto de prueba\n","y_pred = model.predict(X_test)\n","\n","# Calcular la exactitud en el conjunto de prueba\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Exactitud en el conjunto de prueba (Naive Bayes):\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r06bWdfBN4b-","executionInfo":{"status":"ok","timestamp":1684424890134,"user_tz":300,"elapsed":247,"user":{"displayName":"Melissa Tamayo","userId":"11906571870310330412"}},"outputId":"b1b1efc0-67c4-4b49-98a5-05961f7b5097"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Exactitud en el conjunto de prueba (Naive Bayes): 0.8260869565217391\n"]}]},{"cell_type":"markdown","source":["Perceptrón Multicapa:\n","\n","Exactitud en el conjunto de validación: 0.8907\n","El perceptrón multicapa es un modelo de aprendizaje profundo que puede capturar relaciones no lineales complejas en los datos.\n","Sin embargo, en comparación con los otros modelos, el perceptrón multicapa puede ser más propenso al sobreajuste, especialmente si no se ajustan correctamente los hiperparámetros o si el tamaño del conjunto de entrenamiento es pequeño. Esto puede conducir a una disminución en la precisión en el conjunto de validación.\n","\n","Regresión Logística:\n","\n","Exactitud en el conjunto de prueba: 0.9044\n","La regresión logística es un modelo lineal que funciona bien cuando las relaciones entre las características y la variable objetivo son aproximadamente lineales.\n","En comparación con el perceptrón multicapa, la regresión logística puede tener un rendimiento ligeramente mejor en términos de exactitud debido a su capacidad para capturar relaciones lineales entre las características y la variable objetivo. Además, puede ser menos propenso al sobreajuste en comparación con el perceptrón multicapa.\n","\n","Naive Bayes:\n","\n","Exactitud en el conjunto de prueba: 0.8542\n","Naive Bayes es un modelo probabilístico que asume independencia condicional entre las características.\n","En comparación con los otros modelos, Naive Bayes puede tener un rendimiento ligeramente inferior en términos de exactitud debido a sus suposiciones de independencia entre las características. Si las características del conjunto de datos están correlacionadas o violan la suposición de independencia, el rendimiento de Naive Bayes puede verse afectado negativamente."],"metadata":{"id":"WVs_FTGdPNSc"}}]}